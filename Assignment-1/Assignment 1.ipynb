{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSc 8830: Computer Vision - Assignment 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the OAK-D camera, set up your application to show a RGB stream from the mono camera and a depth map stream from the stereo camera simultaneously. Make a note of what is the maximum frame rate and resolution achievable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install depthai & opencv-python\n",
    "!pip install depthai opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "\n",
    "# Parameters\n",
    "# Resolution setting for the RGB camera\n",
    "RGB_RESOLUTION = dai.ColorCameraProperties.SensorResolution.THE_1080_P\n",
    "\n",
    "# Resolution setting for the mono cameras  \n",
    "DEPTH_RESOLUTION = dai.MonoCameraProperties.SensorResolution.THE_400_P\n",
    "\n",
    "# Dimension for resizing the RGB frame  \n",
    "DIM = (720, 480)  \n",
    "\n",
    "# Stereo depth parameters\n",
    "extended_disp = False  # Flag for enabling extended disparity range\n",
    "sub_pixelel = False  # Flag for enabling sub-pixel disparity refinement\n",
    "lr_check = True  # Flag for enabling left-right consistency check\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Camera configurations\n",
    "camera_rgb = pipeline.create(dai.node.ColorCamera)\n",
    "camera_rgb.setResolution(RGB_RESOLUTION)  # Set the resolution for the RGB camera\n",
    "xout_rgb = pipeline.createXLinkOut()\n",
    "xout_rgb.setStreamName(\"rgb\")\n",
    "camera_rgb.video.link(xout_rgb.input)\n",
    "\n",
    "left = pipeline.createMonoCamera()\n",
    "left.setResolution(DEPTH_RESOLUTION)  # Set the resolution for the left mono camera\n",
    "left.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "\n",
    "right = pipeline.createMonoCamera()\n",
    "right.setResolution(DEPTH_RESOLUTION)  # Set the resolution for the right mono camera\n",
    "right.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "depth = pipeline.createStereoDepth()\n",
    "depth.setExtendedDisparity(extended_disp)  # Set whether to enable extended disparity range\n",
    "depth.setSubpixel(sub_pixelel)  # Set whether to enable sub-pixel disparity refinement\n",
    "depth.setLeftRightCheck(lr_check)  # Set whether to enable left-right consistency check\n",
    "left.out.link(depth.left)\n",
    "right.out.link(depth.right)\n",
    "\n",
    "xout = pipeline.createXLinkOut()\n",
    "xout.setStreamName(\"disparity\")\n",
    "depth.disparity.link(xout.input)\n",
    "\n",
    "prev_frame_time = 0  # Variable to store the previous frame time\n",
    "\n",
    "with dai.Device(pipeline) as device:\n",
    "    q = device.getOutputQueue(name=\"disparity\", maxSize=4, blocking=False)  # Output queue for disparity frames\n",
    "    q_rgb = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)  # Output queue for RGB frames\n",
    "    \n",
    "    while True:\n",
    "        new_frame_time = time.time()  # Get current time for FPS calculation\n",
    "        fps = 1 / (new_frame_time - prev_frame_time) if prev_frame_time else 0  # Calculate frames per second\n",
    "        prev_frame_time = new_frame_time\n",
    "        \n",
    "        # Display RGB frame\n",
    "        if q_rgb and q_rgb.has():\n",
    "            in_rgb = q_rgb.get()\n",
    "            frame_rgb = cv.resize(in_rgb.getCvFrame(), DIM, interpolation=cv.INTER_AREA)\n",
    "            cv.imshow(\"rgb\", frame_rgb)\n",
    "        \n",
    "        # Display depth map\n",
    "        if q and q.has():\n",
    "            in_disparity = q.get()  # Blocking call, waits until new data is available\n",
    "            frame = in_disparity.getFrame()\n",
    "            if frame is not None:\n",
    "                # Normalization for better visualization\n",
    "                frame = (frame * (255 / depth.initialConfig.getMaxDisparity())).astype(np.uint8)\n",
    "                cv.imshow(\"disparity\", frame)\n",
    "\n",
    "        print(\"FPS:\", int(fps))  # Print FPS in the console\n",
    "        \n",
    "        key = cv.waitKey(1)  # Wait for key press\n",
    "        if key == ord('q'):  # Break the loop if 'q' is pressed\n",
    "            cv.destroyAllWindows()  # Close all OpenCV windows\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Report the calibration matrix for the camera chosen and verify (using an example) the same. \n",
    "#### 2. Point the camera to a chessboard pattern or any known set of reference points that lie on the same plane. Capture a series of 10 images by changing the orientation of the camera in each iteration. Select any 1 image, and using the image formation pipeline equation, set up the linear equations in matrix form and solve for intrinsic and extrinsic parameters (extrinsic for that particular orientation). You will need to make measurements of the actual 3D world points, and mark pixel coordinates. Once you compute the Rotation matrix, you also need to compute the angles of rotation along each axis. Choose your order of rotation based on your experimentation setup. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing and calibrating cameras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_15176/2350202949.py:83: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline, usb2Mode=True) as device:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image 1 from RGB camera...\n",
      "Image 1 captured from RGB camera\n",
      "Capturing image 2 from RGB camera...\n",
      "Image 2 captured from RGB camera\n",
      "Capturing image 3 from RGB camera...\n",
      "Image 3 captured from RGB camera\n",
      "Capturing image 4 from RGB camera...\n",
      "Image 4 captured from RGB camera\n",
      "Capturing image 5 from RGB camera...\n",
      "Image 5 captured from RGB camera\n",
      "Capturing image 6 from RGB camera...\n",
      "Image 6 captured from RGB camera\n",
      "Capturing image 7 from RGB camera...\n",
      "Image 7 captured from RGB camera\n",
      "Capturing image 8 from RGB camera...\n",
      "Image 8 captured from RGB camera\n",
      "Capturing image 9 from RGB camera...\n",
      "Image 9 captured from RGB camera\n",
      "Capturing image 10 from RGB camera...\n",
      "Image 10 captured from RGB camera\n",
      "Calibrating cameras...\n",
      "Corners not found for images/rgb/17106200177439.png\n",
      "Corners not found for images/rgb/17106200243587.png\n",
      "Corners not found for images/rgb/17106200199564.png\n",
      "Corners not found for images/rgb/17106200210600.png\n",
      "Saving camera matrix...\n",
      "Saving distortion vector...\n",
      "Saving rotational vectors...\n",
      "Saving translation vectors...\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "from pathlib import Path\n",
    "\n",
    "'''\n",
    "    Function to capture 10 images from the specified source (RIGHT or LEFT monochrome camera or RGB camera of OAK-D Lite).\n",
    "    Images are captured at intervals of delay milliseconds.\n",
    "    \n",
    "    Params: \n",
    "        src = {'right' || 'left' || 'rgb'} (default: 'right')\n",
    "        delay = delay in milliseconds (default: 1000)\n",
    "'''\n",
    "\n",
    "def captureImages(src='right', delay=1000, num_imgs = 10):\n",
    "    if src not in ['right', 'left', 'rgb']: \n",
    "        print(\"ENTER CORRECT PARAMS!\")\n",
    "        print(\"accepted params: {left, right, rgb} \")\n",
    "        print(f\"entered src: {src}\")\n",
    "        return;\n",
    "    \n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - mono (grayscale) camera\n",
    "    cam = pipeline.createMonoCamera()\n",
    "    if src == 'right':\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "    elif src == 'left':\n",
    "        cam.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "    else:\n",
    "        print(\"Invalid source for monochrome camera\")\n",
    "        return\n",
    "\n",
    "    cam.setResolution(dai.MonoCameraProperties.SensorResolution.THE_480_P)\n",
    "\n",
    "    # Create output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(src)\n",
    "    cam.out.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline, usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the grayscale frames from the output defined above\n",
    "        q = device.getOutputQueue(name=src, maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/{src}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(num_imgs):\n",
    "            print(f\"Capturing image {i+1} from {src} camera...\")\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            cv.imshow(src, frame)\n",
    "\n",
    "            cv.imwrite(f\"images/{src}/{int(time.time() * 10000)}.png\", frame)\n",
    "            print(f\"Image {i+1} captured from {src} camera\")\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()            \n",
    "\n",
    "\n",
    "def captureColorImages(delay=1000, num_imgs = 10):\n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - color camera\n",
    "    cam = pipeline.createColorCamera()\n",
    "    cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "\n",
    "    # Create RGB output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(\"rgb\")\n",
    "    cam.video.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline, usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the color frames from the output defined above\n",
    "        q = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/rgb\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(num_imgs):\n",
    "            print(f\"Capturing image {i+1} from RGB camera...\")\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            imS = cv.resize(frame, (960, 540)) # Resize image\n",
    "            cv.imshow(\"rgb\", imS)   \n",
    "#             cv.imshow(\"rgb\", frame)\n",
    "\n",
    "            cv.imwrite(f\"images/rgb/{int(time.time() * 10000)}.png\", frame)\n",
    "            print(f\"Image {i+1} captured from RGB camera\")\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "'''\n",
    "    Function to find corners, calibrate, and store camera matrix and distortion vector from the specified source \n",
    "    (RIGHT or LEFT monochrome camera or RGB camera of OAK-D Lite).\n",
    "    \n",
    "    Params: \n",
    "        images = array of image paths\n",
    "        src = source file {'right' || 'left' || 'rgb'} \n",
    "'''\n",
    "\n",
    "def caliberate(images, src):\n",
    "    if src not in ['right', 'left', 'rgb']: \n",
    "        print(\"ENTER CORRECT PARAMS!\")\n",
    "        print(\"accepted params: {left, right, rgb} \")\n",
    "        print(f\"entered src: {src}\")\n",
    "        return;\n",
    "\n",
    "    # Termination criteria\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((6*9, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []  # 3D point in real world space\n",
    "    imgpoints = []  # 2D points in image plane\n",
    "\n",
    "    notFound = []\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Finding chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(gray, (9, 6), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv.drawChessboardCorners(img, (9, 6), corners2, ret)\n",
    "            cv.imshow('img', img)\n",
    "\n",
    "            # Saving displayed corners for future references\n",
    "            cv.imwrite(f\"{fname.split('.')[0]}_corners.png\", img)\n",
    "            cv.waitKey(1000)\n",
    "            cv.destroyAllWindows()\n",
    "        else:\n",
    "            # If corners not found, store the file name in the notFound list\n",
    "            notFound.append(fname)\n",
    "            print(f\"Corners not found for {fname}\")\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # Remove the images whose corners weren't found from the main image list\n",
    "    for i in notFound:\n",
    "        images.remove(i)\n",
    "\n",
    "    # Camera calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv.imread(fname)\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "        # Undistort the image\n",
    "        dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "        # Crop the image\n",
    "        x, y, w, h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "\n",
    "        # Save the undistorted image\n",
    "        cv.imwrite(f\"{fname.split('.')[0]}_result.png\", dst)\n",
    "\n",
    "    # Save camera matrix and distortion coefficients for future use\n",
    "    print(\"Saving camera matrix...\")\n",
    "    np.savetxt(f\"images/{src}/camera_matrix.txt\", mtx)\n",
    "    print(\"Saving distortion vector...\")\n",
    "    np.savetxt(f\"images/{src}/distortion_vector.txt\", dist)\n",
    "    print(\"Saving rotational vectors...\")\n",
    "    np.savetxt(f\"images/{src}/rotation_vectors.txt\", np.array(rvecs).reshape(-1, 3))\n",
    "    print(\"Saving translation vectors...\")\n",
    "    np.savetxt(f\"images/{src}/translation_vectors.txt\", np.array(tvecs).reshape(-1, 3))\n",
    "    print('Done!!')\n",
    "\n",
    "\n",
    "# Capture images and calibrate cameras\n",
    "print(\"Capturing and calibrating cameras...\")\n",
    "# Capture images using the right monochrome camera\n",
    "captureImages('right')\n",
    "# Capture images using the left monochrome camera\n",
    "captureImages('left')\n",
    "# Capture images using the color camera\n",
    "captureColorImages()\n",
    "\n",
    "# Get paths of captured images\n",
    "right_images = glob.glob('images/right/*.png')\n",
    "color_images = glob.glob('images/rgb/*.png')\n",
    "left_images = glob.glob('images/left/*.png')\n",
    "\n",
    "# Calibrate cameras\n",
    "print(\"Calibrating cameras...\")\n",
    "caliberate(right_images, 'right')\n",
    "caliberate(left_images, 'left')\n",
    "caliberate(color_images, 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Square in mm: 32.32487685307927\n",
      "Calibration Error: 2.3248768530792674 mm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_camera_data(camera_matrix_file, distortion_vector_file):\n",
    "    camera_matrix = []\n",
    "    extrinsic_matrix = []\n",
    "    with open(camera_matrix_file, 'r') as f:\n",
    "        for line in f:\n",
    "            camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "    with open(distortion_vector_file, 'r') as f:\n",
    "        for line in f:\n",
    "            extrinsic_matrix.append([float(num) for num in line.split(' ')])\n",
    "    return np.array(camera_matrix), np.array(extrinsic_matrix)\n",
    "\n",
    "def undistort_image(img, camera_matrix, extrinsic_matrix):\n",
    "    h, w = img.shape[:2]\n",
    "    new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, extrinsic_matrix, (w, h), 1, (w, h))\n",
    "    dst = cv2.undistort(img, camera_matrix, extrinsic_matrix, None, new_camera_mtx)\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    return dst\n",
    "\n",
    "def calculate_calibration_error(corners, camera_matrix, obj_dist, known_square_size_mm):\n",
    "    ret, corners = cv2.findChessboardCorners(corners, (9, 6), None)\n",
    "    focal_length_pixels = (camera_matrix[0, 0] + camera_matrix[1, 1]) / 2\n",
    "    if ret:\n",
    "        square_size_pixels = np.linalg.norm(corners[3] - corners[4])\n",
    "        square_size_mm = (square_size_pixels / focal_length_pixels) * obj_dist \n",
    "        print(f\"Size of Square in mm: {square_size_mm}\")\n",
    "        error = abs(square_size_mm - known_square_size_mm)\n",
    "        return error\n",
    "    return None\n",
    "\n",
    "img_to_undistort = cv2.imread('images/left/17104637414935.png')\n",
    "camera_matrix, extrinsic_matrix = load_camera_data('images/left/camera_matrix.txt', 'images/left/distortion_vector.txt')\n",
    "undistorted_img = undistort_image(img_to_undistort, camera_matrix, extrinsic_matrix)\n",
    "gray = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2GRAY)\n",
    "known_square_size_mm = 30  # Set the known size of the chessboard square in mm\n",
    "obj_dist = 200  # Set the distance of the object from the camera in mm\n",
    "calibration_error = calculate_calibration_error(gray, camera_matrix, obj_dist, known_square_size_mm)\n",
    "if calibration_error is not None:\n",
    "    print(f\"Calibration Error: {calibration_error} mm\")\n",
    "else:\n",
    "    print(\"Chessboard corners not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Camera Matrix:\n",
      "[[210.45781727   0.         315.89660879]\n",
      " [  0.         210.13076857 238.12538675]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "Extrinsic Rotation Matrix:\n",
      "[[-0.99901378 -0.04423422 -0.00384739]\n",
      " [ 0.04406837 -0.9983854   0.0358409 ]\n",
      " [-0.00542657  0.03563601  0.9993501 ]] \n",
      "\n",
      "Extrinsic Translation Vector:\n",
      "[[130.86988591]\n",
      " [ 84.19519903]\n",
      " [169.59623503]] \n",
      "\n",
      "Rotation Angles across X, Y, Z axes (degrees):\n",
      "[  2.04225521   0.31092111 177.47421327] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load the chessboard image\n",
    "chessboard_img = cv2.imread('images/left/17104637414935.png')\n",
    "gray_img = cv2.cvtColor(chessboard_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find the chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray_img, (9, 6), None)\n",
    "\n",
    "if ret:\n",
    "    # Refine the corner positions\n",
    "    refined_corners = cv2.cornerSubPix(gray_img, corners, (11, 11), (-1, -1), \n",
    "                                       (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "    \n",
    "    # Draw the corners on the image\n",
    "    cv2.drawChessboardCorners(chessboard_img, (9, 6), refined_corners, ret)\n",
    "    cv2.imshow('Corners', chessboard_img)\n",
    "    cv2.waitKey(5)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Extract image points for PnP\n",
    "top_left_corner = refined_corners[0].ravel()     # Top-left corner in the image\n",
    "top_right_corner = refined_corners[7].ravel()    # Top-right corner in the image\n",
    "bottom_right_corner = refined_corners[-1].ravel()  # Bottom-right corner in the image\n",
    "bottom_left_corner = refined_corners[-8].ravel()   # Bottom-left corner in the image\n",
    "\n",
    "# 2D image points\n",
    "img_points = np.array([top_left_corner, top_right_corner, bottom_right_corner, bottom_left_corner])\n",
    "\n",
    "# Define 3D real-world points\n",
    "obj_points = np.array([[0, 0, 0], [216, 0, 0], [216, 162, 0], [0, 162, 0]], dtype='float32')\n",
    "\n",
    "# Solve PnP\n",
    "ret, rvecs, tvecs = cv2.solvePnP(obj_points, img_points, camera_matrix, extrinsic_matrix)\n",
    "\n",
    "# Convert rotation vectors to rotation matrix\n",
    "rotation_matrix, _ = cv2.Rodrigues(rvecs)\n",
    "\n",
    "# Function to convert rotation matrix to euler angles\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# Convert rotation matrix to euler angles\n",
    "euler_angles = np.degrees(rotation_matrix_to_euler_angles(rotation_matrix))\n",
    "\n",
    "# Print results\n",
    "print(\"Intrinsic Camera Matrix:\")\n",
    "print(camera_matrix, \"\\n\")\n",
    "print(\"Extrinsic Rotation Matrix:\")\n",
    "print(rotation_matrix, \"\\n\")\n",
    "print(\"Extrinsic Translation Vector:\")\n",
    "print(tvecs, \"\\n\")\n",
    "print(\"Rotation Angles across X, Y, Z axes (degrees):\")\n",
    "print(euler_angles, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Write a script to find the real world dimensions (e.g. diameter of a ball, side length of a cube) of an object using perspective projection equations. Validate using an experiment where you image an object using your camera from a specific distance (choose any distance but ensure you are able to measure it accurately) between the object and camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/flgh8s7960bc7q380pyn0c6m0000gn/T/ipykernel_19060/3528505210.py:22: DeprecationWarning: Use constructor taking 'UsbSpeed' instead\n",
      "  with dai.Device(pipeline, usb2Mode=True) as device:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing image 1 from RGB camera...\n",
      "Image 1 captured from RGB camera\n",
      "Capturing image 2 from RGB camera...\n",
      "Image 2 captured from RGB camera\n",
      "Capturing image 3 from RGB camera...\n",
      "Image 3 captured from RGB camera\n",
      "Capturing image 4 from RGB camera...\n",
      "Image 4 captured from RGB camera\n",
      "Capturing image 5 from RGB camera...\n",
      "Image 5 captured from RGB camera\n",
      "Capturing image 6 from RGB camera...\n",
      "Image 6 captured from RGB camera\n",
      "Capturing image 7 from RGB camera...\n",
      "Image 7 captured from RGB camera\n",
      "Capturing image 8 from RGB camera...\n",
      "Image 8 captured from RGB camera\n",
      "Capturing image 9 from RGB camera...\n",
      "Image 9 captured from RGB camera\n",
      "Capturing image 10 from RGB camera...\n",
      "Image 10 captured from RGB camera\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "from pathlib import Path\n",
    "\n",
    "def captureColorImages(delay=1000, num_imgs = 10):\n",
    "    # Start defining a pipeline\n",
    "    pipeline = dai.Pipeline()\n",
    "\n",
    "    # Define a source - color camera\n",
    "    cam = pipeline.createColorCamera()\n",
    "    cam.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)\n",
    "\n",
    "    # Create RGB output\n",
    "    xout = pipeline.createXLinkOut()\n",
    "    xout.setStreamName(\"rgb\")\n",
    "    cam.video.link(xout.input)\n",
    "\n",
    "    # Connect and start the pipeline\n",
    "    with dai.Device(pipeline, usb2Mode=True) as device:\n",
    "\n",
    "        # Output queue will be used to get the color frames from the output defined above\n",
    "        q = device.getOutputQueue(name=\"rgb\", maxSize=4, blocking=False)\n",
    "\n",
    "        # Make sure the destination path is present before starting to store the examples\n",
    "        Path(f\"images/object/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for i in range(num_imgs):\n",
    "            print(f\"Capturing image {i+1} from RGB camera...\")\n",
    "            # Blocking call, will wait until a new data has arrived\n",
    "            inSrc = q.get()  \n",
    "            # Data is originally represented as a flat 1D array, it needs to be converted into HxW form\n",
    "            frame = inSrc.getCvFrame()\n",
    "            # Frame is transformed and ready to be shown\n",
    "            imS = cv.resize(frame, (960, 540)) # Resize image\n",
    "            cv.imshow(\"rgb\", imS)   \n",
    "#             cv.imshow(\"rgb\", frame)\n",
    "\n",
    "            cv.imwrite(f\"images/object/circular_object_{i+1}.png\", frame)\n",
    "            print(f\"Image {i+1} captured from RGB camera\")\n",
    "            cv.waitKey(delay)  \n",
    "\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "# Capture images using the color camera\n",
    "captureColorImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Intrinsic Matrix:  [[210.45781726943, 0.0, 315.89660878657725], [0.0, 210.13076857289957, 238.1253867521593], [0.0, 0.0, 1.0]]\n",
      "fx: 210.45781726943, fy: 210.13076857289957, Z: 300\n",
      "Center (x, y): 877, 575; Width (w): 486; Height (h): 486\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import depthai as dai\n",
    "from pathlib import Path\n",
    "\n",
    "def find_circle_properties(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Use HoughCircles to detect circles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50, param1=100, param2=30, minRadius=10, maxRadius=250)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = circles[0, :]\n",
    "\n",
    "        # Assuming there is only one circle, get its properties\n",
    "        x, y, r = circles[0]\n",
    "\n",
    "        # Calculate center point\n",
    "        center = (int(x), int(y))\n",
    "\n",
    "        # Calculate width and height (diameter)\n",
    "        width = int(2 * r)\n",
    "        height = int(2 * r)\n",
    "\n",
    "        return center, width, height\n",
    "    else:\n",
    "        print(\"No circle detected in the image.\")\n",
    "        return None, None, None\n",
    "\n",
    "camera_matrix = []\n",
    " \n",
    "with open('images/left/camera_matrix.txt', 'r') as f:\n",
    "    for line in f :\n",
    "        camera_matrix.append([float(num) for num in line.split(' ')])\n",
    "\n",
    "print(\"Camera Intrinsic Matrix: \", camera_matrix)\n",
    "\n",
    "img_path = \"images/object/circular_object_10.png\"\n",
    "object_dist = 300 # distance of object from camera in mm\n",
    "\n",
    "# Provide the focal length in pixels (fx)\n",
    "# Provide the focal length in pixels (fy)\n",
    "# Provide the distance to the object in millimeters (Z)\n",
    "\n",
    "fx, fy, Z = camera_matrix[0][0], camera_matrix[1][1], object_dist\n",
    "(x, y), w, h = find_circle_properties(img_path)\n",
    "bbox = (x, y, w, h)  # Provide the bounding box coordinates\n",
    "\n",
    "print(f\"fx: {fx}, fy: {fy}, Z: {Z}\")\n",
    "print(f\"Center (x, y): {x}, {y}; Width (w): {w}; Height (h): {h}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real World Co-ordinates: \n",
      "\t 1250.1317528309107\n",
      "\t 820.917380027359\n",
      "\t 1942.9071597588722\n",
      "\t 1945.9311112648525\n",
      "\n",
      "Diameter of circular object is: 104.03 mm\n"
     ]
    }
   ],
   "source": [
    "def convert_milli_to_inch(x):\n",
    "    x = x / 10\n",
    "    return x / 25.4\n",
    "\n",
    "def calculate_object_distance(image, bbox, fx, fy, Z):\n",
    "    # Unpack bounding box coordinates\n",
    "    x, y, w, h = bbox\n",
    "\n",
    "    # Calculate image points\n",
    "    Image_point1x = x\n",
    "    Image_point1y = y\n",
    "    Image_point2x = x + w\n",
    "    Image_point2y = y + h\n",
    "\n",
    "    # Draw a line between two points\n",
    "    cv2.line(image, (Image_point1x, Image_point1y-h//2), (Image_point1x, Image_point2y-h//2), (0, 0, 255), 8)\n",
    "\n",
    "    # Convert image points to real-world coordinates\n",
    "    Real_point1x = Z * (Image_point1x / fx)\n",
    "    Real_point1y = Z * (Image_point1y / fy)\n",
    "    Real_point2x = Z * (Image_point2x / fx)\n",
    "    Real_point2y = Z * (Image_point2x / fy)\n",
    "\n",
    "    print(\"Real World Co-ordinates: \")\n",
    "    print(\"\\t\", Real_point1x)\n",
    "    print(\"\\t\", Real_point1y)\n",
    "    print(\"\\t\", Real_point2x)\n",
    "    print(\"\\t\", Real_point2y)\n",
    "\n",
    "    # Calculate the distance between two points\n",
    "    dist = math.sqrt((Real_point2y - Real_point1y) ** 2 + (Real_point2x - Real_point1x) ** 2)\n",
    "\n",
    "    val = round(convert_milli_to_inch(dist*2)*10, 2)\n",
    "\n",
    "    # Draw text on the image with the calculated distance\n",
    "    cv2.putText(image, str(val)+\" mm\", (Image_point1x - 200, (y + h) // 2 + 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imwrite(\"circilar_object.png\", image)\n",
    "\n",
    "    return val\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "distance = calculate_object_distance(image, bbox, fx, fy, Z)\n",
    "print(\"\\nDiameter of circular object is: {} mm\".format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
